{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d7e08e5-bf03-4196-97dc-f81ac7fbef05",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41d7b90c-c9ad-4869-ae9c-0ce9b755598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from models.architectures import srgan, srflow\n",
    "import PIL\n",
    "import os\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import pandas as pd\n",
    "\n",
    "# Dataset loading\n",
    "from data import dataloading\n",
    "from data.era5_temp_dataset import InverseMinMaxScaler\n",
    "\n",
    "from os.path import exists, join\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import transforms\n",
    "import timeit\n",
    "import pdb\n",
    "import argparse\n",
    "import seaborn as sns\n",
    "\n",
    "from utils.metrics import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf303f0b-d257-450b-9402-0709994f1cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs avail: 1\n"
     ]
    }
   ],
   "source": [
    "print('GPUs avail:', torch.cuda.device_count())\n",
    "\n",
    "# Parse Settings\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# train configs\n",
    "parser.add_argument(\"--model\", type=str, default=\"srflow\",\n",
    "                    help=\"Model you want to train.\")\n",
    "parser.add_argument(\"--modeltype\", type=str, default=\"srflow\",\n",
    "                    help=\"Specify modeltype you would like to train [srflow, cdiff, srgan].\")\n",
    "parser.add_argument(\"--model_path\", type=str, default=\"runs/\",\n",
    "                    help=\"Directory where models are saved.\")\n",
    "parser.add_argument(\"--modelname\", type=str, default=None,\n",
    "                    help=\"Sepcify modelname to be tested.\")\n",
    "parser.add_argument(\"--epochs\", type=int, default=10000,\n",
    "                    help=\"number of epochs\")\n",
    "parser.add_argument(\"--max_steps\", type=int, default=2000000,\n",
    "                    help=\"For training on a large dataset.\")\n",
    "parser.add_argument(\"--log_interval\", type=int, default=100,\n",
    "                    help=\"Interval in which results should be logged.\")\n",
    "\n",
    "# runtime configs\n",
    "parser.add_argument(\"--visual\", action=\"store_true\",\n",
    "                    help=\"Visualizing the samples at test time.\")\n",
    "parser.add_argument(\"--noscaletest\", action=\"store_true\",\n",
    "                    help=\"Disable scale in coupling layers only at test time.\")\n",
    "parser.add_argument(\"--noscale\", action=\"store_true\",\n",
    "                    help=\"Disable scale in coupling layers.\")\n",
    "parser.add_argument(\"--testmode\", action=\"store_true\",\n",
    "                    help=\"Model run on test set.\")\n",
    "parser.add_argument(\"--train\", action=\"store_true\",\n",
    "                    help=\"If model should be trained.\")\n",
    "parser.add_argument(\"--resume_training\", action=\"store_true\",\n",
    "                    help=\"If training should be resumed.\")\n",
    "parser.add_argument(\"--constraint\", type=str, default='scaddDS',\n",
    "                    help=\"Physical Constraint to be applied during training.\")                   \n",
    "\n",
    "# hyperparameters\n",
    "parser.add_argument(\"--nbits\", type=int, default=8,\n",
    "                    help=\"Images converted to n-bit representations.\")\n",
    "parser.add_argument(\"--s\", type=int, default=16, help=\"Upscaling factor.\")\n",
    "parser.add_argument(\"--bsz\", type=int, default=16, help=\"batch size\")\n",
    "parser.add_argument(\"--lr\", type=float, default=0.0002, help=\"learning rate\")\n",
    "parser.add_argument(\"--filter_size\", type=int, default=512, help=\"filter size NN in Affine Coupling Layer\")\n",
    "parser.add_argument(\"--L\", type=int, default=3, help=\"# of levels\")\n",
    "parser.add_argument(\"--K\", type=int, default=2,\n",
    "                    help=\"# of flow steps, i.e. model depth\")\n",
    "parser.add_argument(\"--nb\", type=int, default=16,\n",
    "                    help=\"# of residual-in-residual blocks LR network.\")\n",
    "parser.add_argument(\"--condch\", type=int, default=128//8,\n",
    "                    help=\"# of residual-in-residual blocks in LR network.\")\n",
    "\n",
    "# data\n",
    "parser.add_argument(\"--datadir\", type=str, default=\"/home/christina/Documents/clim-var-ds-cnf-own/data/\",\n",
    "                    help=\"Dataset to train the model on.\")\n",
    "parser.add_argument(\"--trainset\", type=str, default=\"era5-TCW\", help='[era5-TCW, era5-T2M]')\n",
    "parser.add_argument(\"--testset\", type=str, default=\"era5-TCW\", help=\"Specify test dataset\")\n",
    "\n",
    "args = parser.parse_args('')\n",
    "config = vars(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b59199d9-ddfe-4f61-9996-f3c2cdde57a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    args.device = torch.device(\"cuda\")\n",
    "    args.num_gpus = torch.cuda.device_count()\n",
    "    args.parallel = False\n",
    "\n",
    "else:\n",
    "    args.device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d3eae76-6cfb-47a1-96ad-b2285e4070f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use min-max due to non-gaussian distribution of data and outlier handling\n",
    "def min_max_scaler(x, min_val=0, max_val=124):\n",
    "    if min_val is None:\n",
    "        min_val = x.min()\n",
    "    if max_val is None:\n",
    "        max_val = x.max()\n",
    "    scaled_x = (x - min_val) / (max_val - min_val)\n",
    "    return scaled_x, min_val, max_val\n",
    "\n",
    "def inv_min_max_scaler(scaled_x, min_val=0, max_val=124):\n",
    "    x = scaled_x * (max_val - min_val) + min_val\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1e7190a-dee1-4360-9ff4-1295164c4c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "def load_model(exp_dir, model, mpath):\n",
    "    \"\"\"\n",
    "    Load a model from the specified directory and checkpoint file.\n",
    "    \n",
    "    Parameters:\n",
    "    exp_dir (str): The experiment directory path.\n",
    "    model (torch.nn.Module): The model instance to load the state dictionary into.\n",
    "    mpath (str): The path to the model checkpoint file.\n",
    "    \n",
    "    Returns:\n",
    "    torch.nn.Module: The loaded model with the state dictionary.\n",
    "    \n",
    "    Raises:\n",
    "    FileNotFoundError: If the model file does not exist at the specified path.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if the file exists\n",
    "        if not os.path.exists(mpath):\n",
    "            raise FileNotFoundError(f\"Model file not found at {mpath}\")\n",
    "        \n",
    "        # Load the checkpoint\n",
    "        ckpt = torch.load(mpath)\n",
    "        \n",
    "        # Load the state dictionary into the model\n",
    "        model.load_state_dict(ckpt['model_state_dict'])\n",
    "        \n",
    "        print(\"Model loaded successfully.\")\n",
    "        return model\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f40f74-4d8f-4c05-8efd-36e0db120ac7",
   "metadata": {},
   "source": [
    "### Metric Evaluation\n",
    "Evaluations: \n",
    "- CNF unconstrained vs. constrained\n",
    "- CNF vs. GAN vs. CDiff\n",
    "- Residual Error Plots for ???\n",
    "- Metrics for 2x,4x,8x,16x with and without constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b6ba868-c3fe-44af-82ac-71f748b9e82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torchvision.utils as vutils\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "from utils import metrics\n",
    "\n",
    "def save_snapshot(tensor, path):\n",
    "    # Function to save tensor as image in Viridis color scheme\n",
    "    plt.figure()\n",
    "    plt.imshow(tensor[0,...].cpu().numpy().squeeze(), cmap='viridis')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(path, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "def save_grid_images(tensor_batch, save_path, nrow=3, title=None):\n",
    "    \n",
    "    # Create a grid of images\n",
    "    grid_img = vutils.make_grid(tensor_batch[0:9], nrow=nrow, normalize=True, scale_each=True)\n",
    "\n",
    "    # Convert the grid to numpy and plot\n",
    "    np_grid = grid_img.cpu().numpy().transpose((1, 2, 0))\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(np_grid[:, :, 0], cmap='viridis')  # Use Viridis colormap for grayscale images\n",
    "    plt.axis('off')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout(pad=0)\n",
    "\n",
    "    # Save the grid image\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "def metric_eval(dataloader, model, exp_name, args):\n",
    "    metric_dict = {\n",
    "        'rmse0': [], 'mse0': [], 'mae0': [],\n",
    "        'rmse05': [], 'mse05': [], 'mae05': [],\n",
    "        'rmse08': [], 'mse08': [], 'mae08': [],\n",
    "        'rmse1': [], 'mse1': [], 'mae1': [],\n",
    "        'crps0': [], 'crps05': [],'crps08': [],'crps1': [],\n",
    "    }\n",
    "\n",
    "    # Create directories\n",
    "    results_dir = os.path.join(exp_name, 'experiment_results')\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    snapshots_dir = os.path.join(results_dir, 'snapshots')\n",
    "    os.makedirs(snapshots_dir, exist_ok=True)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, item in enumerate(dataloader):\n",
    "            y = item[0].to(args.device)\n",
    "            x = item[1].to(args.device)\n",
    "\n",
    "            y_unorm = item[2].to(args.device)\n",
    "            x_unorm = item[3].to(args.device)\n",
    "\n",
    "            z, _ = model.forward(x_hr=y, xlr=x)\n",
    "\n",
    "            # Evaluate for different temperatures\n",
    "            mu0, _, _ = model(xlr=x, reverse=True, eps=0)\n",
    "            mu05, _, _ = model(xlr=x, reverse=True, eps=0.5)\n",
    "            mu08, _, _ = model(xlr=x, reverse=True, eps=0.8)\n",
    "            mu1, _, _ = model(xlr=x, reverse=True, eps=1.0)\n",
    "\n",
    "            # Compute and store MSE for each temperature\n",
    "            mse0 = metrics.MSE(inv_min_max_scaler(mu0), y_unorm).detach().cpu().numpy()\n",
    "            mse05 = metrics.MSE(inv_min_max_scaler(mu05), y_unorm).detach().cpu().numpy()\n",
    "            mse08 = metrics.MSE(inv_min_max_scaler(mu08), y_unorm).detach().cpu().numpy()\n",
    "            mse1 = metrics.MSE(inv_min_max_scaler(mu1), y_unorm).detach().cpu().numpy()\n",
    "            \n",
    "            metric_dict['mse0'].append(mse0)\n",
    "            metric_dict['mse05'].append(mse05)\n",
    "            metric_dict['mse08'].append(mse08)\n",
    "            metric_dict['mse1'].append(mse1)\n",
    "\n",
    "            # Compute and store MAE for each temperature\n",
    "            mae0 = metrics.MAE(inv_min_max_scaler(mu0), y_unorm).detach().cpu().numpy()\n",
    "            mae05 = metrics.MAE(inv_min_max_scaler(mu05), y_unorm).detach().cpu().numpy()\n",
    "            mae08 = metrics.MAE(inv_min_max_scaler(mu08), y_unorm).detach().cpu().numpy()\n",
    "            mae1 = metrics.MAE(inv_min_max_scaler(mu1), y_unorm).detach().cpu().numpy()\n",
    "\n",
    "            metric_dict['mae0'].append(mae0)\n",
    "            metric_dict['mae05'].append(mae05)\n",
    "            metric_dict['mae08'].append(mae08)\n",
    "            metric_dict['mae1'].append(mae1)\n",
    "\n",
    "            # Compute and store RMSE for each temperature\n",
    "            rmse0 = metrics.RMSE(inv_min_max_scaler(mu0), y_unorm).detach().cpu().numpy()\n",
    "            rmse05 = metrics.RMSE(inv_min_max_scaler(mu05), y_unorm).detach().cpu().numpy()\n",
    "            rmse08 = metrics.RMSE(inv_min_max_scaler(mu08), y_unorm).detach().cpu().numpy()\n",
    "            rmse1 = metrics.RMSE(inv_min_max_scaler(mu1), y_unorm).detach().cpu().numpy()\n",
    "\n",
    "            metric_dict['rmse0'].append(rmse0)\n",
    "            metric_dict['rmse05'].append(rmse05)\n",
    "            metric_dict['rmse08'].append(rmse08)\n",
    "            metric_dict['rmse1'].append(rmse1)\n",
    "\n",
    "             # Calculate CRPS for ensemble\n",
    "            metric_dict['crps0'].append(crps_ensemble(y_unorm, inv_min_max_scaler(mu0)))\n",
    "            metric_dict['crps05'].append(crps_ensemble(y_unorm, inv_min_max_scaler(mu05)))\n",
    "            metric_dict['crps08'].append(crps_ensemble(y_unorm, inv_min_max_scaler(mu08)))\n",
    "            metric_dict['crps1'].append(crps_ensemble(y_unorm, inv_min_max_scaler(mu1)))\n",
    "            \n",
    "            # Save grid of images for visualization (adjust as needed)\n",
    "            if batch_idx == 0:  # Save only for the first batch for simplicity\n",
    "                # Save snapshots\n",
    "                save_grid_images(y_unorm, os.path.join(snapshots_dir, f'ground_truth_{batch_idx}.png'))\n",
    "                save_grid_images(mu0, os.path.join(snapshots_dir, f'prediction_mu0_{batch_idx}.png'))\n",
    "                save_grid_images(mu05, os.path.join(snapshots_dir, f'prediction_mu05_{batch_idx}.png'))\n",
    "                save_grid_images(mu08, os.path.join(snapshots_dir, f'prediction_mu08_{batch_idx}.png'))\n",
    "                save_grid_images(mu1, os.path.join(snapshots_dir, f'prediction_mu1_{batch_idx}.png'))\n",
    "                save_grid_images(x_unorm, os.path.join(snapshots_dir, f'low_res_{batch_idx}.png'))\n",
    "                \n",
    "            print(f'Current RMSE - mu0: {rmse0}, mu05: {rmse05}, mu08: {rmse08}, mu1: {rmse1}')\n",
    "            print(f'Current MAE - mu0: {mae0}, mu05: {mae05}, mu08: {mae08}, mu1: {mae1}')\n",
    "            # print(f'Current CRPS - mu0:{crps0}, mu05: {crps05}, mu08: {crps08}, m1: {crps1}')\n",
    "\n",
    "            # if batch_idx == 200:\n",
    "            #     break\n",
    "\n",
    "    # Create a string representation of the metric_dict\n",
    "    mean_dict = {}\n",
    "    for key, value in metric_dict.items():\n",
    "        if len(value) > 0:\n",
    "            mean_dict[key] = np.mean(value)   \n",
    "            \n",
    "    metric_str = \"\\n\".join([f\"{key}: {value}\" for key, value in mean_dict.items()])\n",
    "\n",
    "    # Save metric_dict to a text file\n",
    "    with open(os.path.join(results_dir, 'metrics.txt'), 'w') as f:\n",
    "        json.dump(metric_str, f, indent=4)\n",
    "        \n",
    "    print(metric_dict)\n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a8bc6b-680f-4948-9907-4974e3e7ac0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d0b1ea6-82ef-47c3-b12c-5218d3d5229d",
   "metadata": {},
   "source": [
    "# Experiments: Comparing across upsampling factors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "336f9b86-94ba-4ba6-aa51-2a2bcb6c322b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of avail GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "print('Num of avail GPUs:', torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0022d1-64a6-4afb-87ec-ecf73572ad87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b44a420e-e59f-4b93-9a70-7f6523e0089d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21223"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "533cb3e7-9282-4cf0-b5eb-31d39fc3a8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args.s = 2\n",
    "# train_loader, val_loader, test_loader, args = dataloading.load_data(args)\n",
    "# in_channels = next(iter(test_loader))[0].shape[1]\n",
    "# height, width = next(iter(test_loader))[0].shape[2], next(iter(test_loader))[0].shape[3]\n",
    "# cnf2x = srflow.SRFlow((in_channels, height, width), args.filter_size, args.L, args.K, args.bsz, 2, args.constraint, args.nb, args.condch, args.noscale, args.noscaletest)\n",
    "# exp_dir = 'runs/srflow_era5-TCW_None_2024_06_22_09_31_04_2x/'\n",
    "# cnf_path = '/home/christina/Documents/clim-var-ds-cnf-own/runs/srflow_era5-TCW_None_2024_06_22_09_31_04_2x/model_checkpoints/model_epoch_0_step_2000.tar'\n",
    "# # Load the model\n",
    "# cnf2x = load_model(exp_dir, cnf2x, cnf_path).to(args.device)\n",
    "# metric_eval(test_loader, cnf2x, exp_dir, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40b6d0d8-40e7-4219-9ce2-3885c493c5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada11319-96bd-444c-843c-791a51369f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ERA5 TCW ...\n",
      "Model loaded successfully.\n",
      "torch.Size([16, 1, 128, 128]) torch.Size([16, 1, 128, 128])\n",
      "Current RMSE - mu0: 0.7782304286956787, mu05: 0.8744242191314697, mu08: 1.01076078414917, mu1: 1.119126319885254\n",
      "Current MAE - mu0: 0.4996071457862854, mu05: 0.5784834623336792, mu08: 0.6809549331665039, mu1: 0.7605693340301514\n",
      "torch.Size([16, 1, 128, 128]) torch.Size([16, 1, 128, 128])\n",
      "Current RMSE - mu0: 1.0036119222640991, mu05: 1.1076695919036865, mu08: 1.2780117988586426, mu1: 1.3793339729309082\n",
      "Current MAE - mu0: 0.6312191486358643, mu05: 0.7165780067443848, mu08: 0.8373243808746338, mu1: 0.9231313467025757\n",
      "torch.Size([16, 1, 128, 128]) torch.Size([16, 1, 128, 128])\n",
      "Current RMSE - mu0: 0.8366748094558716, mu05: 0.9491092562675476, mu08: 1.1023550033569336, mu1: 1.2323195934295654\n",
      "Current MAE - mu0: 0.528417706489563, mu05: 0.6191744804382324, mu08: 0.73700350522995, mu1: 0.8255254030227661\n",
      "torch.Size([16, 1, 128, 128]) torch.Size([16, 1, 128, 128])\n",
      "Current RMSE - mu0: 1.0915640592575073, mu05: 1.2073955535888672, mu08: 1.3871347904205322, mu1: 1.513817310333252\n",
      "Current MAE - mu0: 0.6820089817047119, mu05: 0.7748874425888062, mu08: 0.9022209644317627, mu1: 0.9974349737167358\n",
      "torch.Size([16, 1, 128, 128]) torch.Size([16, 1, 128, 128])\n",
      "Current RMSE - mu0: 0.8378251194953918, mu05: 0.9511082768440247, mu08: 1.1018377542495728, mu1: 1.220322847366333\n",
      "Current MAE - mu0: 0.5548107624053955, mu05: 0.6464317440986633, mu08: 0.7605609893798828, mu1: 0.8517892360687256\n",
      "torch.Size([16, 1, 128, 128]) torch.Size([16, 1, 128, 128])\n",
      "Current RMSE - mu0: 0.811310887336731, mu05: 0.9092361330986023, mu08: 1.0738935470581055, mu1: 1.1689834594726562\n",
      "Current MAE - mu0: 0.5020104646682739, mu05: 0.5812193751335144, mu08: 0.6957949995994568, mu1: 0.7703269720077515\n",
      "torch.Size([16, 1, 128, 128]) torch.Size([16, 1, 128, 128])\n",
      "Current RMSE - mu0: 0.8206019997596741, mu05: 0.913805365562439, mu08: 1.039701223373413, mu1: 1.1548397541046143\n",
      "Current MAE - mu0: 0.5428884625434875, mu05: 0.6188690662384033, mu08: 0.7158007621765137, mu1: 0.7989251613616943\n",
      "torch.Size([16, 1, 128, 128]) torch.Size([16, 1, 128, 128])\n",
      "Current RMSE - mu0: 0.8456293344497681, mu05: 0.943622350692749, mu08: 1.0836877822875977, mu1: 1.2169156074523926\n",
      "Current MAE - mu0: 0.5479449033737183, mu05: 0.6257032752037048, mu08: 0.7243980169296265, mu1: 0.813882052898407\n"
     ]
    }
   ],
   "source": [
    "args.s = 4\n",
    "train_loader, val_loader, test_loader, args = dataloading.load_data(args)\n",
    "in_channels = next(iter(test_loader))[0].shape[1]\n",
    "height, width = next(iter(test_loader))[0].shape[2], next(iter(test_loader))[0].shape[3]\n",
    "cnf4x = srflow.SRFlow((in_channels, height, width), args.filter_size, args.L, args.K, args.bsz, 4, args.constraint, args.nb, args.condch, args.noscale, args.noscaletest)\n",
    "exp_dir = 'runs/srflow_era5-TCW_None_2024_06_22_09_00_21_4x/'\n",
    "cnf_path = '/home/christina/Documents/clim-var-ds-cnf-own/runs/srflow_era5-TCW_None_2024_06_22_09_00_21_4x/model_checkpoints/model_epoch_0_step_2000.tar'\n",
    "# Load the model\n",
    "cnf4x = load_model(exp_dir, cnf4x, cnf_path).to(args.device)\n",
    "metric_eval(test_loader, cnf4x, exp_dir, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6de1c2d-f081-48cb-95c0-07666a2257c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d1c7b4-7265-4295-a0f3-107826c45266",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.s = 8\n",
    "args.device = 'cuda'\n",
    "train_loader, val_loader, test_loader, args = dataloading.load_data(args)\n",
    "in_channels = next(iter(test_loader))[0].shape[1]\n",
    "height, width = next(iter(test_loader))[0].shape[2], next(iter(test_loader))[0].shape[3]\n",
    "cnf8x = srflow.SRFlow((in_channels, height, width), args.filter_size, args.L, args.K, args.bsz, 8, args.constraint, args.nb, args.condch, args.noscale, args.noscaletest)\n",
    "exp_dir = 'runs/srflow_era5-TCW_None_2024_06_22_09_00_20_8x/'\n",
    "cnf_path = '/home/christina/Documents/clim-var-ds-cnf-own/runs/srflow_era5-TCW_None_2024_06_22_09_00_20_8x/model_checkpoints/model_epoch_2_step_5750.tar'\n",
    "# Load the model\n",
    "cnf8x = load_model(exp_dir, cnf8x, cnf_path).to(args.device)\n",
    "metric_eval(test_loader, cnf8x, exp_dir, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c584e157-a39b-4293-bb1c-a73a3d28f5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db1cdd4-2f74-48aa-ba38-7878fa28f4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.s = 16\n",
    "args.device = 'cuda'\n",
    "train_loader, val_loader, test_loader, args = dataloading.load_data(args)\n",
    "in_channels = next(iter(test_loader))[0].shape[1]\n",
    "height, width = next(iter(test_loader))[0].shape[2], next(iter(test_loader))[0].shape[3]\n",
    "cnf16x = srflow.SRFlow((in_channels, height, width), args.filter_size, args.L, args.K, args.bsz, 16, args.constraint, args.nb, args.condch, args.noscale, args.noscaletest)\n",
    "exp_dir = 'runs/srflow_era5-TCW_None_2024_06_22_09_00_13_16x/'\n",
    "cnf_path = '/home/christina/Documents/clim-var-ds-cnf-own/runs/srflow_era5-TCW_None_2024_06_22_09_00_13_16x/model_checkpoints/model_epoch_2_step_5750.tar'\n",
    "# Load the model\n",
    "cnf16x = load_model(exp_dir, cnf16x, cnf_path).to(args.device)\n",
    "metric_eval(test_loader, cnf16x, exp_dir, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3725bf-cc8e-41fb-ab3f-ce2088f40626",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a48072-d21e-4428-b9d3-391ea4a32304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_std(model):\n",
    "    \"\"\"\n",
    "    For this experiment we visualize the super-resolution space for a single\n",
    "    low-resolution image and its possible HR target predictions. We visualize\n",
    "    the standard deviation of these predictions from the mean of the model.\n",
    "    \"\"\"\n",
    "    color = 'plasma'\n",
    "    savedir_viz = \"experiments/{}_{}_{}/snapshots/population_std/\".format(exp_name, modelname, args.trainset)\n",
    "    os.makedirs(savedir_viz, exist_ok=True)\n",
    "    model.eval()\n",
    "    cmap = 'viridis' if args.trainset == 'era5-TCW' else 'inferno'\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, item in enumerate(test_loader):\n",
    "\n",
    "            y = item[0].to(args.device)\n",
    "            x = item[1].to(args.device)\n",
    "\n",
    "            y_unorm = item[2].to(args.device)\n",
    "            x_unnorm = item[3].to(args.device)\n",
    "\n",
    "            mu0 = model(x)\n",
    "\n",
    "            samples = []\n",
    "            n = 20\n",
    "            sq_diff = torch.zeros_like(mu0)\n",
    "            for n in range(n):\n",
    "                mu1 = model(x)\n",
    "                samples.append(mu0)\n",
    "                sq_diff += (mu1 - mu0)**2\n",
    "\n",
    "            # compute population standard deviation\n",
    "            sigma = torch.sqrt(sq_diff / n)\n",
    "\n",
    "            # create plot\n",
    "            plt.figure()\n",
    "            plt.imshow(sigma[0,...].permute(1,2,0).cpu().numpy(), cmap=color)\n",
    "            plt.axis('off')\n",
    "            # plt.show()\n",
    "            plt.savefig(savedir_viz + '/sigma_{}.png'.format(batch_idx), dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "            plt.figure()\n",
    "            plt.imshow(mu0[0,...].permute(1,2,0).cpu().numpy(), cmap=cmap)\n",
    "            plt.axis('off')\n",
    "            # plt.show()\n",
    "            plt.savefig(savedir_viz + '/mu0_{}.png'.format(batch_idx), dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "            fig, (ax1, ax3, ax4, ax5, ax6, ax7) = plt.subplots(1,6)\n",
    "            # fig.suptitle('Y, Y_hat, mu, sigma')\n",
    "            ax1.imshow(y[0,...].permute(1,2,0).cpu().numpy(), cmap=cmap)\n",
    "            divider = make_axes_locatable(ax1)\n",
    "            cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "            cax.set_axis_off()\n",
    "            ax1.set_title('Ground Truth', fontsize=5)\n",
    "            ax1.axis('off')\n",
    "            # ax2.imshow(mu0[0,...].permute(1,2,0).cpu().numpy(), cmap=cmap)\n",
    "            # divider = make_axes_locatable(ax2)\n",
    "            # cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "            # cax.set_axis_off()\n",
    "            # ax2.set_title('Mean', fontsize=5)\n",
    "            # ax2.axis('off')\n",
    "            ax3.imshow(samples[1][0,...].permute(1,2,0).cpu().numpy(), cmap=cmap)\n",
    "            divider = make_axes_locatable(ax3)\n",
    "            cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "            cax.set_axis_off()\n",
    "            ax3.set_title('Sample 1', fontsize=5)\n",
    "            ax3.axis('off')\n",
    "            ax4.imshow(samples[2][0,...].permute(1,2,0).cpu().numpy(), cmap=cmap)\n",
    "            divider = make_axes_locatable(ax4)\n",
    "            cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "            cax.set_axis_off()\n",
    "            ax4.set_title('Sample 2', fontsize=5)\n",
    "            ax4.axis('off')\n",
    "            ax5.imshow(samples[2][0,...].permute(1,2,0).cpu().numpy(), cmap=cmap)\n",
    "            divider = make_axes_locatable(ax5)\n",
    "            cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "            cax.set_axis_off()\n",
    "            ax5.set_title('Sample 3', fontsize=5)\n",
    "            ax5.axis('off')\n",
    "            ax6.imshow(samples[2][0,...].permute(1,2,0).cpu().numpy(), cmap=cmap)\n",
    "            divider = make_axes_locatable(ax6)\n",
    "            cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "            cax.set_axis_off()\n",
    "            ax6.set_title('Sample 4', fontsize=5)\n",
    "            ax6.axis('off')\n",
    "            divider = make_axes_locatable(ax7)\n",
    "            cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "            im7 = ax7.imshow(sigma[0,...].permute(1,2,0).cpu().numpy(), cmap='magma')\n",
    "            cbar = fig.colorbar(im7,cmap='magma', cax=cax)\n",
    "            cbar.ax.tick_params(labelsize=5)\n",
    "            ax7.set_title('Std. Dev.', fontsize=5)\n",
    "            ax7.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(savedir_viz + '/std_multiplot_{}.png'.format(batch_idx), dpi=300, bbox_inches='tight')\n",
    "            # plt.show()\n",
    "            plt.close()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d94cf2-be70-45b4-89bf-9c06d2fcea3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb177aea-61e3-4ab7-8174-bb8fa402a398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b22e9e-7ce6-4c74-a3ac-81fc674e883f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264f30ab-bb5c-4557-9df9-718fdae3fd54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d985bf-522e-4548-ba2d-69b4332e988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# especially focus on analyzing extreme value predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8ab0b0-40db-4250-87aa-eca4e1baa5a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99064919-f20b-41f1-aefc-51d7ac0a4725",
   "metadata": {},
   "source": [
    "### Scatter Plot (Predicted vs Target)\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7d44f7-7c96-40d1-8486-a50ab42e2946",
   "metadata": {},
   "source": [
    "### Cumulative Distribution of  Residual Errors\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe4910b-9bf2-48bb-846d-ad2ec5cdbc0a",
   "metadata": {},
   "source": [
    "### Experiments: Constraint placement\n",
    "Comparing model with no constraint vs. multiplicative constraint at output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9347584c-ab9d-438c-9fab-df805258236c",
   "metadata": {},
   "source": [
    "### Load CNF with constraints 4x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1deda00-919a-4bf8-9aba-24c58aaf084b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_4x_add = srflow.SRFlow((in_channels, height, width), args.filter_size, args.L, args.K, args.bsz, 4, 'add', args.nb, args.condch, args.noscale, args.noscaletest)\n",
    "cnf_4x_mult = srflow.SRFlow((in_channels, height, width), args.filter_size, args.L, args.K, args.bsz, 4, 'mult', args.nb, args.condch, args.noscale, args.noscaletest)\n",
    "cnf_4x_scadd = srflow.SRFlow((in_channels, height, width), args.filter_size, args.L, args.K, args.bsz, 4, 'scadd', args.nb, args.condch, args.noscale, args.noscaletest)\n",
    "cnf_4x_softmax = srflow.SRFlow((in_channels, height, width), args.filter_size, args.L, args.K, args.bsz, 4, 'softmax', args.nb, args.condch, args.noscale, args.noscaletest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcd5591-1151-40f9-a8d5-02923a8a0324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load vanilla conditional flow 4x\n",
    "exp_dir_add_4x = 'runs/srflow_era5-TCW_None_2024_06_22_09_00_21_4x/'\n",
    "exp_dir_mult_4x = 'runs/srflow_era5-TCW_None_2024_06_22_09_00_21_4x/'\n",
    "exp_dir_scadd_4x = 'runs/srflow_era5-TCW_None_2024_06_22_09_00_21_4x/'\n",
    "exp_dir_softmax_4x = 'runs/srflow_era5-TCW_None_2024_06_22_09_00_21_4x/'\n",
    "\n",
    "cnf_4x_add_path = '/home/christina/Documents/clim-var-ds-cnf-own/runs/srflow_era5-TCW_None_2024_06_22_09_00_21_4x/model_checkpoints/model_epoch_0_step_2000.tar'\n",
    "cnf_4x_mult_path = '/home/christina/Documents/clim-var-ds-cnf-own/runs/srflow_era5-TCW_None_2024_06_22_09_00_21_4x/model_checkpoints/model_epoch_0_step_2000.tar'\n",
    "cnf_4x_scadd_path = '/home/christina/Documents/clim-var-ds-cnf-own/runs/srflow_era5-TCW_None_2024_06_22_09_00_21_4x/model_checkpoints/model_epoch_0_step_2000.tar'\n",
    "cnf_4x_softmax_path = '/home/christina/Documents/clim-var-ds-cnf-own/runs/srflow_era5-TCW_None_2024_06_22_09_00_21_4x/model_checkpoints/model_epoch_0_step_2000.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e927c773-49e9-4536-8063-4bcec81e24ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2x watercontent mul with constraint at the end \n",
    "modelname = 'model_epoch_0_step_1000'\n",
    "modelpath = '/home/mila/c/christina.winkler/clim-var-ds-cnf/runs/srflow_era5-TCW_mul_ constr_in_end__2024_06_03_17_35_33_2x/model_checkpoints/{}.tar'.format(modelname)\n",
    "\n",
    "model = srflow.SRFlow((in_channels, args.height, args.width), args.filter_size, args.L, args.K,\n",
    "                        args.bsz, args.s, 'mul', args.nb, args.condch, args.noscale, args.noscaletest)\n",
    "\n",
    "params = sum(x.numel() for x in model.parameters() if x.requires_grad)\n",
    "print('Nr of Trainable Params {}:  '.format(args.device), params)\n",
    "model = model.to(args.device)\n",
    "exp_name = \"flow-{}-level-{}-k--constraint-{}\".format(args.L, args.K, 'mul')\n",
    "print(exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61cfb41-ce31-4839-95ee-3022fcb39730",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(modelpath, map_location='cuda:0')\n",
    "model.load_state_dict(ckpt['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6755db-4ebb-440e-9fb6-6fe490faccdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stflow",
   "language": "python",
   "name": "stflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
