{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "733180e5-fca2-4b7a-933e-166dc9f7136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from models.architectures import srgan, srflow\n",
    "import PIL\n",
    "import os\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Dataset loading\n",
    "from data import dataloading\n",
    "from data.era5_temp_dataset import InverseMinMaxScaler\n",
    "\n",
    "from os.path import exists, join\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import transforms\n",
    "import timeit\n",
    "import pdb\n",
    "import argparse\n",
    "import seaborn as sns\n",
    "\n",
    "from utils.metrics import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47fdd29b-411d-4666-a1a1-db12ce1ec18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs avail: 1\n"
     ]
    }
   ],
   "source": [
    "print('GPUs avail:', torch.cuda.device_count())\n",
    "\n",
    "# Parse Settings\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# train configs\n",
    "parser.add_argument(\"--model\", type=str, default=\"srflow\",\n",
    "                    help=\"Model you want to train.\")\n",
    "parser.add_argument(\"--modeltype\", type=str, default=\"srflow\",\n",
    "                    help=\"Specify modeltype you would like to train [srflow, cdiff, srgan].\")\n",
    "parser.add_argument(\"--model_path\", type=str, default=\"runs/\",\n",
    "                    help=\"Directory where models are saved.\")\n",
    "parser.add_argument(\"--modelname\", type=str, default=None,\n",
    "                    help=\"Sepcify modelname to be tested.\")\n",
    "parser.add_argument(\"--epochs\", type=int, default=10000,\n",
    "                    help=\"number of epochs\")\n",
    "parser.add_argument(\"--max_steps\", type=int, default=2000000,\n",
    "                    help=\"For training on a large dataset.\")\n",
    "parser.add_argument(\"--log_interval\", type=int, default=100,\n",
    "                    help=\"Interval in which results should be logged.\")\n",
    "\n",
    "# runtime configs\n",
    "parser.add_argument(\"--visual\", action=\"store_true\",\n",
    "                    help=\"Visualizing the samples at test time.\")\n",
    "parser.add_argument(\"--noscaletest\", action=\"store_true\",\n",
    "                    help=\"Disable scale in coupling layers only at test time.\")\n",
    "parser.add_argument(\"--noscale\", action=\"store_true\",\n",
    "                    help=\"Disable scale in coupling layers.\")\n",
    "parser.add_argument(\"--testmode\", action=\"store_true\",\n",
    "                    help=\"Model run on test set.\")\n",
    "parser.add_argument(\"--train\", action=\"store_true\",\n",
    "                    help=\"If model should be trained.\")\n",
    "parser.add_argument(\"--resume_training\", action=\"store_true\",\n",
    "                    help=\"If training should be resumed.\")\n",
    "parser.add_argument(\"--constraint\", type=str, default='scaddDS',\n",
    "                    help=\"Physical Constraint to be applied during training.\")                   \n",
    "\n",
    "# hyperparameters\n",
    "parser.add_argument(\"--nbits\", type=int, default=8,\n",
    "                    help=\"Images converted to n-bit representations.\")\n",
    "parser.add_argument(\"--s\", type=int, default=16, help=\"Upscaling factor.\")\n",
    "parser.add_argument(\"--bsz\", type=int, default=16, help=\"batch size\")\n",
    "parser.add_argument(\"--lr\", type=float, default=0.0002, help=\"learning rate\")\n",
    "parser.add_argument(\"--filter_size\", type=int, default=512, help=\"filter size NN in Affine Coupling Layer\")\n",
    "parser.add_argument(\"--L\", type=int, default=3, help=\"# of levels\")\n",
    "parser.add_argument(\"--K\", type=int, default=2,\n",
    "                    help=\"# of flow steps, i.e. model depth\")\n",
    "parser.add_argument(\"--nb\", type=int, default=16,\n",
    "                    help=\"# of residual-in-residual blocks LR network.\")\n",
    "parser.add_argument(\"--condch\", type=int, default=128//8,\n",
    "                    help=\"# of residual-in-residual blocks in LR network.\")\n",
    "\n",
    "# data\n",
    "parser.add_argument(\"--datadir\", type=str, default=\"/home/christina/Documents/clim-var-ds-cnf-own/data/\",\n",
    "                    help=\"Dataset to train the model on.\")\n",
    "parser.add_argument(\"--trainset\", type=str, default=\"era5-TCW\", help='[era5-TCW, era5-T2M]')\n",
    "parser.add_argument(\"--testset\", type=str, default=\"era5-TCW\", help=\"Specify test dataset\")\n",
    "\n",
    "args = parser.parse_args('')\n",
    "config = vars(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48095964-a950-49e0-9b32-acfabaad69a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a44c1e-fc1d-45f1-a98c-23d7a8733234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68fcef3-240c-46cd-aa08-69113418ce93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15b88a7-322c-4929-9766-fac539cbfc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_std(model):\n",
    "    \"\"\"\n",
    "    For this experiment we visualize the super-resolution space for a single\n",
    "    low-resolution image and its possible HR target predictions. We visualize\n",
    "    the standard deviation of these predictions from the mean of the model.\n",
    "    \"\"\"\n",
    "    color = 'plasma'\n",
    "    savedir_viz = \"experiments/{}_{}_{}/snapshots/population_std/\".format(exp_name, modelname, args.trainset)\n",
    "    os.makedirs(savedir_viz, exist_ok=True)\n",
    "    model.eval()\n",
    "    cmap = 'viridis' if args.trainset == 'era5-TCW' else 'inferno'\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, item in enumerate(test_loader):\n",
    "\n",
    "            y = item[0].to(args.device)\n",
    "            x = item[1].to(args.device)\n",
    "\n",
    "            y_unorm = item[2].to(args.device)\n",
    "            x_unnorm = item[3].to(args.device)\n",
    "\n",
    "            mu0 = model(x)\n",
    "\n",
    "            samples = []\n",
    "            n = 20\n",
    "            sq_diff = torch.zeros_like(mu0)\n",
    "            for n in range(n):\n",
    "                mu1 = model(x)\n",
    "                samples.append(mu0)\n",
    "                sq_diff += (mu1 - mu0)**2\n",
    "\n",
    "            # compute population standard deviation\n",
    "            sigma = torch.sqrt(sq_diff / n)\n",
    "\n",
    "            # create plot\n",
    "            plt.figure()\n",
    "            plt.imshow(sigma[0,...].permute(1,2,0).cpu().numpy(), cmap=color)\n",
    "            plt.axis('off')\n",
    "            # plt.show()\n",
    "            plt.savefig(savedir_viz + '/sigma_{}.png'.format(batch_idx), dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "            plt.figure()\n",
    "            plt.imshow(mu0[0,...].permute(1,2,0).cpu().numpy(), cmap=cmap)\n",
    "            plt.axis('off')\n",
    "            # plt.show()\n",
    "            plt.savefig(savedir_viz + '/mu0_{}.png'.format(batch_idx), dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "            fig, (ax1, ax3, ax4, ax5, ax6, ax7) = plt.subplots(1,6)\n",
    "            # fig.suptitle('Y, Y_hat, mu, sigma')\n",
    "            ax1.imshow(y[0,...].permute(1,2,0).cpu().numpy(), cmap=cmap)\n",
    "            divider = make_axes_locatable(ax1)\n",
    "            cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "            cax.set_axis_off()\n",
    "            ax1.set_title('Ground Truth', fontsize=5)\n",
    "            ax1.axis('off')\n",
    "            # ax2.imshow(mu0[0,...].permute(1,2,0).cpu().numpy(), cmap=cmap)\n",
    "            # divider = make_axes_locatable(ax2)\n",
    "            # cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "            # cax.set_axis_off()\n",
    "            # ax2.set_title('Mean', fontsize=5)\n",
    "            # ax2.axis('off')\n",
    "            ax3.imshow(samples[1][0,...].permute(1,2,0).cpu().numpy(), cmap=cmap)\n",
    "            divider = make_axes_locatable(ax3)\n",
    "            cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "            cax.set_axis_off()\n",
    "            ax3.set_title('Sample 1', fontsize=5)\n",
    "            ax3.axis('off')\n",
    "            ax4.imshow(samples[2][0,...].permute(1,2,0).cpu().numpy(), cmap=cmap)\n",
    "            divider = make_axes_locatable(ax4)\n",
    "            cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "            cax.set_axis_off()\n",
    "            ax4.set_title('Sample 2', fontsize=5)\n",
    "            ax4.axis('off')\n",
    "            ax5.imshow(samples[2][0,...].permute(1,2,0).cpu().numpy(), cmap=cmap)\n",
    "            divider = make_axes_locatable(ax5)\n",
    "            cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "            cax.set_axis_off()\n",
    "            ax5.set_title('Sample 3', fontsize=5)\n",
    "            ax5.axis('off')\n",
    "            ax6.imshow(samples[2][0,...].permute(1,2,0).cpu().numpy(), cmap=cmap)\n",
    "            divider = make_axes_locatable(ax6)\n",
    "            cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "            cax.set_axis_off()\n",
    "            ax6.set_title('Sample 4', fontsize=5)\n",
    "            ax6.axis('off')\n",
    "            divider = make_axes_locatable(ax7)\n",
    "            cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "            im7 = ax7.imshow(sigma[0,...].permute(1,2,0).cpu().numpy(), cmap='magma')\n",
    "            cbar = fig.colorbar(im7,cmap='magma', cax=cax)\n",
    "            cbar.ax.tick_params(labelsize=5)\n",
    "            ax7.set_title('Std. Dev.', fontsize=5)\n",
    "            ax7.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(savedir_viz + '/std_multiplot_{}.png'.format(batch_idx), dpi=300, bbox_inches='tight')\n",
    "            # plt.show()\n",
    "            plt.close()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab18a359-9174-46f8-bf23-cd6109f035a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b05b086-0ce5-431e-9d0d-dfe0a73776e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
